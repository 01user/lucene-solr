= Loading Data
// Licensed to the Apache Software Foundation (ASF) under one
// or more contributor license agreements.  See the NOTICE file
// distributed with this work for additional information
// regarding copyright ownership.  The ASF licenses this file
// to you under the Apache License, Version 2.0 (the
// "License"); you may not use this file except in compliance
// with the License.  You may obtain a copy of the License at
//
//   http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing,
// software distributed under the License is distributed on an
// "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
// KIND, either express or implied.  See the License for the
// specific language governing permissions and limitations
// under the License.


Streaming Expressions allows CSV and TSV formatted data to be visualized and transformed
before loading it into Solr Cloud collections. A number of useful functions are provided
for parsing dates, creating unique ids, cleaning data, analyzing text and visualizing
data all before its loaded into Solr Cloud collections.

== Reading Files

The `cat` function can be used to read files under the "userfiles" directory in
SOLR_HOME. The `cat` function takes two parameters. The first parameter is a comma
delimited list of paths. If the path list contain directories, `cat` will crawl
all the files in the directory and sub-directories. If the path list contains only
files `cat` will operate crawl just the specific files.

The second parameter, *maxLines*, tells `cat` how many lines to read in total. If
*maxLines* is not provided, `cat` will read all lines from each file it crawls.

The `cat` function reads each line (up to maxLines) in files and for each line
emits a tuple with two fields:

* line: The text in the line.
* file: The relative path of the file under SOLR_HOME.

Below is an example of `cat` on the iris.csv file with a maxLines of 5:

[source,text]
----
cat("iris.csv", maxLines="5")
----

When this expression is sent to the `/stream` handler it responds with:

[source,json]
----
{
  "result-set": {
    "docs": [
      {
        "line": "sepal_length,sepal_width,petal_length,petal_width,species",
        "file": "iris.csv"
      },
      {
        "line": "5.1,3.5,1.4,0.2,setosa",
        "file": "iris.csv"
      },
      {
        "line": "4.9,3,1.4,0.2,setosa",
        "file": "iris.csv"
      },
      {
        "line": "4.7,3.2,1.3,0.2,setosa",
        "file": "iris.csv"
      },
      {
        "line": "4.6,3.1,1.5,0.2,setosa",
        "file": "iris.csv"
      },
      {
        "EOF": true,
        "RESPONSE_TIME": 0
      }
    ]
  }
}
----


== Parsing CSV and TSV Files

The `parseCSV` and `parseTSV` functions wrap the `cat` function and parse CSV
(comma separated values) and TSV (tab separated values). Both of these functions
expect a CSV or TSV header record at the beginning of each file.

Both `parseCSV` and `parseTSV` emit tuples with the header values mapped to their
corresponding values in each line.


[source,text]
----
parseCSV(cat("iris.csv", maxLines="5"))
----

When this expression is sent to the `/stream` handler it responds with:

[source,json]
----
{
  "result-set": {
    "docs": [
      {
        "sepal_width": "3.5",
        "species": "setosa",
        "petal_width": "0.2",
        "sepal_length": "5.1",
        "id": "iris.csv_2",
        "petal_length": "1.4"
      },
      {
        "sepal_width": "3",
        "species": "setosa",
        "petal_width": "0.2",
        "sepal_length": "4.9",
        "id": "iris.csv_3",
        "petal_length": "1.4"
      },
      {
        "sepal_width": "3.2",
        "species": "setosa",
        "petal_width": "0.2",
        "sepal_length": "4.7",
        "id": "iris.csv_4",
        "petal_length": "1.3"
      },
      {
        "sepal_width": "3.1",
        "species": "setosa",
        "petal_width": "0.2",
        "sepal_length": "4.6",
        "id": "iris.csv_5",
        "petal_length": "1.5"
      },
      {
        "EOF": true,
        "RESPONSE_TIME": 1
      }
    ]
  }
}
----

== Visualizing

image::images/math-expressions/csvtable.png[]

image::images/math-expressions/csv.png[]


== Transforming Data

=== Selecting fields

=== Unique ID's

Both functions also emit an id field if one is not present in the records already.
The id field is a concatenation of the file path and the line number. This is a
convenent way to ensure that records have consistent reproducible id's if the one
is not present in file.


=== Parsing Dates

=== Handling Nulls

=== String Manipulation

=== Text Analysis

== Loading Data


